{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "arabic-coordinator",
   "metadata": {},
   "source": [
    "## Comparison Approach\n",
    "This notebook loads each of the individual, trained models from the best runs of both Bert and CNN-based approaches. It will show the model.summary() and diagram, then will run a performance test by inferring results for the texts in the ClaimBuster dataset's crowdsourced.csv file. The file contains 22501 sentences. We will use sentences per second as the performance metric, and the on-disk size of each model as the complexity metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "individual-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Usual Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as backend\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.config.experimental import list_physical_devices, set_visible_devices\n",
    "\n",
    "import string\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import matplotlib as plt\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../python')\n",
    "import debug\n",
    "from jbyrne_utils import tokenize_sentences\n",
    "\n",
    "\n",
    "# to fix the CUDA issues for CUDA 11.2 to allow use of the GPU\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-fundamental",
   "metadata": {},
   "source": [
    "### Load the crowdsourced test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coated-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and parse the crowdsourced.csv file\n",
    "\n",
    "cs = pd.read_csv(\"../data/crowdsourced.csv\", delimiter=',', quotechar = '\"', index_col='Sentence_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-insured",
   "metadata": {},
   "source": [
    "Unlike the curated json dataset we used for training, the \"verdict\" column takes three values:\n",
    "\n",
    "| Verdict | Description |\n",
    "| :---: | :--- |\n",
    "| +1 | Checkable Fact Statements, e.g. \"Inflation is down 2%\" |\n",
    "| 0 | Uncheckable Fact Statements, e.g. \"Jack likes fish\" |\n",
    "| -1 | Non Fact Statements, e.g. \"Drink the water\" |\n",
    "\n",
    "For the purposes of this paper, we are only interested in checkable fact statements, so we set any -1 verdicts to equal zero before tokenizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "restricted-election",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14685"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cs.loc[cs[\"Verdict\"] == -1][\"Verdict\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "swiss-onion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 14685 -1 labels.\n",
      "After:  0 -1 labels.\n"
     ]
    }
   ],
   "source": [
    "# Change -1 verdicts (non claim sentences) to be 0.\n",
    "print(f\"Before: {len(cs.loc[cs['Verdict'] == -1])} -1 labels.\")\n",
    "\n",
    "cs.loc[cs[\"Verdict\"] == -1, \"Verdict\"] = 0\n",
    "\n",
    "print(f\"After:  {len(cs.loc[cs['Verdict'] == -1])} -1 labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-blackjack",
   "metadata": {},
   "source": [
    "### Tokenizing the new dataset\n",
    "Provided this is run AFTER the other tests, there should be a tokenizer.pkl and embed_matrix.pkl already created from the training dataset.  We need to encode the new text using the same vocabulary and ID mapping as it will be input into a pre-trained embeddings layer in the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-compound",
   "metadata": {},
   "source": [
    "## Initialize the output dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aggressive-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(columns = [\"Type\",\n",
    "                                 \"Model\",\n",
    "                                 \"Hardware\",\n",
    "                                 \"Max Length\",\n",
    "                                 \"Filters\",\n",
    "                                 \"Dense Layers\",\n",
    "                                 \"Parameter Count\",\n",
    "                                 \"Val Accuracy\",\n",
    "                                 \"Test Accuracy\",\n",
    "                                 \"Inf. Rate/s\",\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-treat",
   "metadata": {},
   "source": [
    "### GPU vs CPU performance\n",
    "As one objective is to run claim detection at the edge, we will be doing performance testing on both GPU and CPU hardware.\n",
    "\n",
    "All work on this project has been done using the following software and hardware:\n",
    "\n",
    "* Anaconda distribution of Python 3.8.2\n",
    "* Tensorflow 2.4.1\n",
    "* AMD Ryzen TR 3970X 32-Core Processor with Hyperthreading (64 threads)\n",
    "* NVidia RTX2080 Super GPU\n",
    "\n",
    "First display the tensorflow IDs for the CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "overhead-metro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daily-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable the GPU for these runs\n",
    "set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-match",
   "metadata": {},
   "source": [
    "## Test the CNN Best models for each max_len\n",
    "We ran a series of grid searches to find the best performing models for each of the tested sentence lengths:\n",
    "\n",
    "| max_len | Description |\n",
    "| :---: | :--- |\n",
    "| 100 | Only 14 of 11056 sentences are truncated, so 99.87% of sentences are processed in full |\n",
    "| 50 | Half the length still processes 95.57% of sentences in full |\n",
    "| 21 | Equal to the rounded average length, processes 61.478% of sentences in full |\n",
    "| 17 | Equal to the median length, processes half the sentences in full |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "every-hawaiian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>max_len</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>embed_dim</th>\n",
       "      <th>num_filters</th>\n",
       "      <th>kernel_sizes</th>\n",
       "      <th>dense_layer_dims</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>val_accuracy_best</th>\n",
       "      <th>val_accuracy_best_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210409-222341</td>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>[16, 32]</td>\n",
       "      <td>[8, 16]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.960669</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  max_len  batch_size  embed_dim num_filters kernel_sizes  \\\n",
       "4  210409-222341       17          50         50    [16, 32]      [8, 16]   \n",
       "\n",
       "  dense_layer_dims  dropout_rate  val_accuracy_best  val_accuracy_best_epoch  \n",
       "4              [8]           0.2           0.960669                        7  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./best_small_models.pkl', 'rb') as f:\n",
    "    best_models = pickle.load(f)\n",
    "best_models = best_models.sort_values('val_accuracy_best', ascending=False)\n",
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bottom-music",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    210409-222341\n",
       "Name: timestamp, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[\"timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "metropolitan-valve",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "CNN Model from timestamp 210409-222341\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 17)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 17, 50)       409800      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 10, 16)       6416        embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 2, 32)        25632       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 16)           0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 32)           0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 48)           0           global_max_pooling1d_8[0][0]     \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 48)           0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 8)            392         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            9           dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 442,249\n",
      "Trainable params: 442,249\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Loading previously created Tokenizer\n",
      "Inferring 100 iterations of test data\n",
      "\n",
      "000.........\n",
      "010.........\n",
      "020.........\n",
      "030.........\n",
      "040.........\n",
      "050.........\n",
      "060.........\n",
      "070.........\n",
      "080.........\n",
      "090.........\n",
      "\n",
      "COMPLETED\n",
      "\n",
      "Time taken for 2,250,100 inferrences = 13.653 s.\n",
      "Rate is 164,807.996 inferrences per second\n"
     ]
    }
   ],
   "source": [
    "cycles = 100\n",
    "\n",
    "\n",
    "def run_perftest(tokens, labels, model, cycles):\n",
    "    print(f\"Inferring {cycles} iterations of test data\")\n",
    "    start_time = datetime.datetime.now()\n",
    "    for i in range(cycles):\n",
    "        history = model.evaluate(tokens, labels, batch_size=128, verbose=0)\n",
    "        if i % 10 == 0:\n",
    "            print(f\"\\n{i:03d}\", end=\"\")\n",
    "        else:\n",
    "            print(\".\", end=\"\")\n",
    "    print('\\n\\nCOMPLETED\\n')\n",
    "                  \n",
    "    end_time = datetime.datetime.now()\n",
    "    difference = end_time - start_time\n",
    "    return (difference.total_seconds(), history)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "for index,row in best_models.iterrows():\n",
    "    timestamp = row[\"timestamp\"]\n",
    "    \n",
    "    model = keras.models.load_model(f'../best_models/{timestamp}')\n",
    "    print(f\"\\n\\n\\nCNN Model from timestamp {timestamp}\")\n",
    "    \n",
    "    # Display summary and diagram of the model\n",
    "    model.summary()\n",
    "    keras.utils.plot_model(model, f'{timestamp}.png', show_shapes=True, show_dtype=True, rankdir=\"TB\")\n",
    "    \n",
    "    tokens, _ = tokenize_sentences(cs[\"Text\"], max_len=row[\"max_len\"] )\n",
    "    labels = cs[\"Verdict\"]\n",
    "    \n",
    "    # Run Performance Test on the crowdsourced test data set\n",
    "    \n",
    "    difference, history = run_perftest(tokens, labels, model, cycles)\n",
    "    \n",
    "    print(f\"Time taken for {cycles * len(labels):,} inferrences = {difference:.3f} s.\")\n",
    "    print(f\"Rate is {cycles * len(labels) / difference:,.3f} inferrences per second\")\n",
    "    \n",
    "    # Add the results to the output\n",
    "    \n",
    "    filter_string = f\"Sizes: {row['kernel_sizes']} Counts: {row['num_filters']}\"\n",
    "    parameter_count = np.sum([backend.count_params(w) for w in model.trainable_weights]) + \\\n",
    "                      np.sum([backend.count_params(w) for w in model.non_trainable_weights])\n",
    "\n",
    "    \n",
    "    record = pd.DataFrame( {\"Type\": \"CNN\",\n",
    "                            \"Model\": timestamp,\n",
    "                            \"Hardware\": \"GPU\",\n",
    "                            \"Max Length\": row[\"max_len\"],\n",
    "                            \"Filters\": filter_string,\n",
    "                            \"Dense Layers\": row[\"dense_layer_dims\"],\n",
    "                            \"Parameter Count\": parameter_count ,\n",
    "                            \"Val Accuracy\": row[\"val_accuracy_best\"],\n",
    "                            \"Test Accuracy\": history[1],\n",
    "                            \"Inf. Rate/s\": cycles * len(labels) / difference\n",
    "                           },\n",
    "                           index = [1]) # timestamp\n",
    "    output = output.append(record)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "future-actress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Model</th>\n",
       "      <th>Hardware</th>\n",
       "      <th>Max Length</th>\n",
       "      <th>Filters</th>\n",
       "      <th>Dense Layers</th>\n",
       "      <th>Parameter Count</th>\n",
       "      <th>Val Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Inf. Rate/s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN</td>\n",
       "      <td>210409-222341</td>\n",
       "      <td>GPU</td>\n",
       "      <td>17</td>\n",
       "      <td>Sizes: [8, 16] Counts: [16, 32]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>442249.0</td>\n",
       "      <td>0.960669</td>\n",
       "      <td>0.883516</td>\n",
       "      <td>164807.995865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type          Model Hardware Max Length                          Filters  \\\n",
       "1  CNN  210409-222341      GPU         17  Sizes: [8, 16] Counts: [16, 32]   \n",
       "\n",
       "  Dense Layers  Parameter Count  Val Accuracy  Test Accuracy    Inf. Rate/s  \n",
       "1          [8]         442249.0      0.960669       0.883516  164807.995865  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-thunder",
   "metadata": {},
   "source": [
    "__210409-222341: max_len = 17__\n",
    "![\"210409-222341\"](./210409-222341.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-region",
   "metadata": {},
   "source": [
    "### Citations\n",
    "@inproceedings{arslan2020claimbuster,\n",
    "    title={{A Benchmark Dataset of Check-worthy Factual Claims}},\n",
    "    author={Arslan, Fatma and Hassan, Naeemul and Li, Chengkai and Tremayne, Mark },\n",
    "    booktitle={14th International AAAI Conference on Web and Social Media},\n",
    "    year={2020},\n",
    "    organization={AAAI}\n",
    "}\n",
    "\n",
    "@article{meng2020gradient,\n",
    "  title={Gradient-Based Adversarial Training on Transformer Networks for Detecting Check-Worthy Factual Claims},\n",
    "  author={Meng, Kevin and Jimenez, Damian and Arslan, Fatma and Devasier, Jacob Daniel and Obembe, Daniel and Li, Chengkai},\n",
    "  journal={arXiv preprint arXiv:2002.07725},\n",
    "  year={2020}\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
