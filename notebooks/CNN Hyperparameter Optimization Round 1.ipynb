{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "occupied-consultation",
   "metadata": {},
   "source": [
    "## CNN sentence classifier \n",
    "\n",
    "I have borrowed heavily from CNN.ipynb in assignment 4 for the code shell here.  I have not used the vocabulary objects however as I wanted to be in control of how the vocab is structured.\n",
    "\n",
    "This is parameterized so we can run multiple cases to pick the best results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "weekly-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enable Tensorboard\n",
    "%load_ext tensorboard\n",
    "\n",
    "## Usual Imports\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "import datetime\n",
    "import string\n",
    "\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "## Requires nltk.download('punkt') if not already in the environment.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Helper libraries\n",
    "from w266_common import utils, vocabulary\n",
    "\n",
    "\n",
    "\n",
    "# to fix the CUDA issues for CUDA 11.2\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nominated-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum number of tokens to look at.\n",
    "max_len = 100\n",
    "embed_dim = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-frequency",
   "metadata": {},
   "source": [
    "## Read in the data set of sentences and store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "talented-twist",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 ms, sys: 276 µs, total: 13.7 ms\n",
      "Wall time: 13 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11056"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Load Data file into numpy array\n",
    "\n",
    "with open(\"../data/3xNCS.json\") as f:\n",
    "    d = np.asarray(json.load(f))\n",
    "\n",
    "# shuffle the array to randomize the data sets used\n",
    "# essential as the file has all the true labels before\n",
    "# the false ones\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(d)\n",
    "\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-instrument",
   "metadata": {},
   "source": [
    "## Split into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "distinct-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.2 ms, sys: 3.99 ms, total: 14.2 ms\n",
      "Wall time: 13.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "train_len = int(0.6 * len(d))\n",
    "val_len = int(0.2 * len(d))\n",
    "\n",
    "train, val, test = np.split(d, [train_len, train_len + val_len])\n",
    "\n",
    "# split into x and y sets for use in keras runs\n",
    "x_train, y_train = np.array( [ i[\"text\"] for i in train ] ), np.array( [ i[\"label\"] for i in train ] )\n",
    "x_val,   y_val   = np.array( [ i[\"text\"] for i in val ] ),   np.array( [ i[\"label\"] for i in val ]   )\n",
    "x_test,  y_test  = np.array( [ i[\"text\"] for i in test ] ),  np.array( [ i[\"label\"] for i in test ]  )\n",
    "\n",
    "## Cant seem to get the binary output to work, so have to one-hot the labels.\n",
    "## separating the code so we can pull it out if I get the binary output working.\n",
    "\n",
    "# y_train = [ [abs(a-1),a] for a in y_train]\n",
    "# y_val   = [ [abs(a-1),a] for a in y_val  ]\n",
    "# y_test  = [ [abs(a-1),a] for a in y_test ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-navigator",
   "metadata": {},
   "source": [
    "## Tokenize the training data set and build a vocabulary from it\n",
    "Want to do this to minimize the vocab to just what is in the training set for performance.\n",
    "\n",
    "using defaults:  strip all punctuation except apostrophies, set to lower case and split on spaces. No restriction on length of vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "charitable-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the training data set and build a vocabulary from it\n",
    "# Want to do this to minimize the vocab to just what is in\n",
    "# the training set for performance.\n",
    "\n",
    "# Defaults of the tokenizer:\n",
    "# set to lower case and split on spaces.\n",
    "# No restriction on length of vocabulary\n",
    "#\n",
    "# Overriding the default filters with string.punctuation\n",
    "# as the default does not strip apostrophies which is\n",
    "# expected in the GloVe tokenizer.\n",
    "\n",
    "\n",
    "\n",
    "t = keras.preprocessing.text.Tokenizer(filters=string.punctuation)\n",
    "\n",
    "t.fit_on_texts(x_train)\n",
    "\n",
    "\n",
    "\n",
    "# Convert the test statements into arrays of index numbers\n",
    "# from the vocabulary that represent each word. and then \n",
    "# pad or truncate to max_len tokens\n",
    "\n",
    "x_train_ids = pad_sequences(t.texts_to_sequences(x_train)\n",
    "                            ,max_len,\n",
    "                            padding='post',\n",
    "                            truncating = 'post')\n",
    "\n",
    "x_val_ids = pad_sequences(t.texts_to_sequences(x_val),\n",
    "                          max_len, \n",
    "                          padding='post', \n",
    "                          truncating = 'post')\n",
    "x_test_ids = pad_sequences(t.texts_to_sequences(x_test),\n",
    "                           max_len, \n",
    "                           padding='post', \n",
    "                           truncating = 'post')\n",
    "\n",
    "# Get list of words in the vocab to filter what we load from the GloVe file\n",
    "vocab_list = list(t.word_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "precious-gazette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7017"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "promotional-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab_list) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "preliminary-gambling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1672"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_train == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rough-paraguay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4961"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_train == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "higher-purse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of checkable to non-checkable in training data  : 0.25207296849087896\n",
      "ratio of checkable to non-checkable in validation data: 0.250565355042967\n",
      "ratio of checkable to non-checkable in test data      : 0.24321880650994576\n"
     ]
    }
   ],
   "source": [
    "# Check for % of statements that are checkable claims to \n",
    "# ensure we have some level of balance that will avoid\n",
    "# high accuracy for single value guessing.\n",
    "\n",
    "print(f\"ratio of checkable to non-checkable in training data  : {np.count_nonzero(y_train == 1)/len(y_train)}\")\n",
    "print(f\"ratio of checkable to non-checkable in validation data: {np.count_nonzero(y_val == 1)/len(y_val)}\")\n",
    "print(f\"ratio of checkable to non-checkable in test data      : {np.count_nonzero(y_test == 1)/len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-preservation",
   "metadata": {},
   "source": [
    "# Function to create embeddings dictionary for the network\n",
    "\n",
    "Defaults to using gloVe.6B.zip for testing - trained with Wikipedia 2014 and Gigaword 5.  Data set is 822Mb, so putting into /mnt/export/NLPData on the file server in a partition with 7TB of free space.  This has 50, 100, 200 and 300 dimension vectors - worth looking at for training vs. accuracy purposes\n",
    "\n",
    "This is the 50 dimension embedding.\n",
    "\n",
    "The function returns the embedding matrix needed for the keras.layers.Embedding() layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bigger-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_matrix(vocab_list, embed_loc = \"/mnt/export/NLPData\", embed_file = \"glove.6B.50d.txt\"):\n",
    "\n",
    "    embed_dict = {}\n",
    "\n",
    "    with open(embed_loc + \"/\" + embed_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            if word in vocab_list:\n",
    "                vector = np.asarray(values[1:], \"float32\")   #Keeps data smaller instead of defaulting to float64\n",
    "                embed_dict[word] = vector\n",
    "\n",
    "    print(len(embed_dict))\n",
    "    \n",
    "    vocab_size = len(t.word_index) + 1\n",
    "    \n",
    "    embedding_matrix = np.zeros((vocab_size, embed_dim))\n",
    "    for word, i in t.word_index.items():\n",
    "        embedding_vector = embed_dict.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            print(f\"Could not find {word} in the GloVe vocab\")\n",
    "            \n",
    "    return(embedding_matrix)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bottom-gather",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6972\n",
      "Could not find hadn in the GloVe vocab\n",
      "Could not find ã‚ in the GloVe vocab\n",
      "Could not find itãâ‚¬s in the GloVe vocab\n",
      "Could not find weã¢â‚¬â„¢ll in the GloVe vocab\n",
      "Could not find midgetman in the GloVe vocab\n",
      "Could not find itã¢â‚¬â„¢s in the GloVe vocab\n",
      "Could not find snipings in the GloVe vocab\n",
      "Could not find recallable in the GloVe vocab\n",
      "Could not find vietnese in the GloVe vocab\n",
      "Could not find namese in the GloVe vocab\n",
      "Could not find insur in the GloVe vocab\n",
      "Could not find ãƒâ¢ã¢â€šâ¬ã¢â‚¬å“ in the GloVe vocab\n",
      "Could not find l981 in the GloVe vocab\n",
      "Could not find 30ãâ‚¬s in the GloVe vocab\n",
      "Could not find 40ãâ‚¬s in the GloVe vocab\n",
      "Could not find insolvable in the GloVe vocab\n",
      "Could not find arterially in the GloVe vocab\n",
      "Could not find braggadocios in the GloVe vocab\n",
      "Could not find aayuh in the GloVe vocab\n",
      "Could not find appropri in the GloVe vocab\n",
      "Could not find l4s in the GloVe vocab\n",
      "Could not find lorranna in the GloVe vocab\n",
      "Could not find shinsheki in the GloVe vocab\n",
      "Could not find communizing in the GloVe vocab\n",
      "Could not find cosigner in the GloVe vocab\n",
      "Could not find ã¢â€°â¥well in the GloVe vocab\n",
      "Could not find thatã¢â‚¬â„¢s in the GloVe vocab\n",
      "Could not find unlistened in the GloVe vocab\n",
      "Could not find donã¢â‚¬â„¢t in the GloVe vocab\n",
      "Could not find ã¢â€°â¥mr in the GloVe vocab\n",
      "Could not find kalikian in the GloVe vocab\n",
      "Could not find presidentã¢â‚¬â„¢s in the GloVe vocab\n",
      "Could not find 20to in the GloVe vocab\n",
      "Could not find proabortion in the GloVe vocab\n",
      "Could not find cardash in the GloVe vocab\n",
      "Could not find roundtabled in the GloVe vocab\n",
      "Could not find bicta in the GloVe vocab\n",
      "Could not find bict in the GloVe vocab\n",
      "Could not find reregistering in the GloVe vocab\n",
      "Could not find democ in the GloVe vocab\n",
      "Could not find outyears in the GloVe vocab\n",
      "Could not find ener1 in the GloVe vocab\n",
      "Could not find dolekemp96 in the GloVe vocab\n",
      "Could not find ã¢â€°â¤ in the GloVe vocab\n",
      "Could not find khadaffi in the GloVe vocab\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = embed_matrix(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abroad-netherlands",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.41800001,  0.24968   , -0.41242   , ..., -0.18411   ,\n",
       "        -0.11514   , -0.78580999],\n",
       "       [ 0.68046999, -0.039263  ,  0.30186   , ..., -0.073297  ,\n",
       "        -0.064699  , -0.26043999],\n",
       "       ...,\n",
       "       [-0.70185   , -0.48587   , -1.1372    , ..., -0.70876002,\n",
       "        -0.73249   , -0.17163   ],\n",
       "       [-0.051174  , -0.36392999, -0.058348  , ...,  0.60711002,\n",
       "        -1.63810003, -0.95243001],\n",
       "       [ 0.68660998, -0.078468  ,  0.20039   , ...,  0.64521003,\n",
       "         0.068449  ,  0.30531999]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "weighted-accident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 9 µs, total: 9 µs\n",
      "Wall time: 14.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### run_model() - a function to build and run the model based on the passed parameters (if any)\n",
    "\n",
    "# Construct the convolutional neural network.\n",
    "# The form of each keras layer function is as follows:\n",
    "#    result = keras.layers.LayerType(arguments for the layer)(layer(s) it should use as input)\n",
    "# concretely,\n",
    "#    this_layer_output = keras.layers.Dense(100, activation='relu')(prev_layer_vector)\n",
    "# performs this_layer_output = relu(prev_layer_vector x W + b) where W has 100 columns.\n",
    "#\n",
    "# Defaults are defined at the top of the notebook\n",
    "\n",
    "\n",
    "\n",
    "def run_model(max_len = max_len,        # set at top of notebook\n",
    "              epochs = 30,\n",
    "              batch_size = 50,\n",
    "              embed_dim = embed_dim,    # set at top of notebook\n",
    "              num_filters = [2, 2, 2],\n",
    "              kernel_sizes = [2, 3, 4],\n",
    "              dense_layer_dims = [8],\n",
    "              dropout_rate = 0.1,\n",
    "              train_embeds = False,  # Whether we allow the embeddings to be changed\n",
    "              opt = 'adam', \n",
    "              log_run_results = False):\n",
    "\n",
    "    num_classes = 1\n",
    "\n",
    "    # set up input layer (receives word IDs) and embedding that tuyrns that into GloVe embeddings\n",
    "    word_ids = keras.layers.Input(shape=(max_len,))\n",
    "    h=keras.layers.Embedding(vocab_size,\n",
    "                             embed_dim,\n",
    "                             weights=[embedding_matrix],\n",
    "                             trainable = train_embeds)(word_ids)\n",
    "\n",
    "    # Add convolutional layers and pooling layers based on number of filters and kernel size(s)\n",
    "    conv_layers_for_all_kernel_sizes = []\n",
    "    for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
    "        print(f\"Adding Convolution: Kernel Size: {kernel_size}, Filter Count: {filters}\")\n",
    "        # note that all convolution layers take the same input \"h\" the output from the embedding layer\n",
    "        conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(h)\n",
    "        conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
    "        conv_layers_for_all_kernel_sizes.append(conv_layer)\n",
    "\n",
    "    # Concat the feature maps from each different size.\n",
    "    h = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)\n",
    "\n",
    "    # Dropout can help with overfitting\n",
    "    h = keras.layers.Dropout(rate=dropout_rate)(h)\n",
    "\n",
    "    # Add the fully connected feed forward layers for categorization\n",
    "    # Add a fully connected layer for each dense layer dimension in dense_layer_dims.\n",
    "    for dim in dense_layer_dims:\n",
    "        h = keras.layers.Dense(dim, activation='relu')(h)\n",
    "\n",
    "    # Add the output layer for classifier - in this case, there is only one output\n",
    "    prediction = keras.layers.Dense(num_classes, activation='sigmoid')(h)\n",
    "\n",
    "    # Create and compile the model\n",
    "    model = keras.Model(inputs=word_ids, outputs=prediction)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',               # as we only have a single output class\n",
    "                  # metrics=['binary_accuracy'])                    # What metric to output as we train.\n",
    "                  metrics=['accuracy'])                    # What metric to output as we train.\n",
    "    \n",
    "    print(model.summary())\n",
    "\n",
    "    model.reset_states()\n",
    "\n",
    "    tag  = datetime.datetime.now().strftime(\"%y%m%d-%H%M%S\")\n",
    "    log_dir = f\"tblogs-{kernel_sizes}/\".replace(\"[\",\"\").replace(\"]\",\"\").replace(\", \",\"\") + \\\n",
    "                datetime.datetime.now().strftime(\"%y%m%d-%H%M%S\")\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    model.fit(x_train_ids, y_train,\n",
    "              epochs=epochs,\n",
    "              batch_size = batch_size,\n",
    "              validation_data = (x_val_ids, y_val),\n",
    "              callbacks=[tensorboard_callback]   )\n",
    "\n",
    "    hist = model.history.history\n",
    "    \n",
    "    if log_run_results:\n",
    "        with open(\"runs.log\", 'a') as f:\n",
    "            f.write(f\"{tag}|{max_len}|{epochs}|{batch_size}|{embed_dim}|{num_filters}|{kernel_sizes}|{dense_layer_dims}|{dropout_rate}|{num_classes}|{train_embeds}|\")\n",
    "            for metric in list(hist.keys()):\n",
    "                print(metric)\n",
    "                f.write(f\"{metric}|\")\n",
    "                for i in range(0,epochs):\n",
    "                    f.write(f\"{hist[metric][i]}|\")\n",
    "            f.write(f\"END\\n\")        \n",
    "            f.close()\n",
    "    \n",
    "    return(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sweet-deputy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Convolution: Kernel Size: 2, Filter Count: 2\n",
      "Adding Convolution: Kernel Size: 3, Filter Count: 2\n",
      "Adding Convolution: Kernel Size: 4, Filter Count: 2\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 100, 50)      350900      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 99, 2)        202         embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 98, 2)        302         embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 97, 2)        402         embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 2)            0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 2)            0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 2)            0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 6)            0           global_max_pooling1d_6[0][0]     \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 6)            0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 8)            56          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            9           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 351,871\n",
      "Trainable params: 971\n",
      "Non-trainable params: 350,900\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 2s 8ms/step - loss: 0.5819 - accuracy: 0.7350 - val_loss: 0.4908 - val_accuracy: 0.7689\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.8000 - val_loss: 0.3784 - val_accuracy: 0.8372\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8408 - val_loss: 0.3595 - val_accuracy: 0.8539\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.8460 - val_loss: 0.3468 - val_accuracy: 0.8575\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.8423 - val_loss: 0.3404 - val_accuracy: 0.8544\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3645 - accuracy: 0.8452 - val_loss: 0.3370 - val_accuracy: 0.8566\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8557 - val_loss: 0.3347 - val_accuracy: 0.8589\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8585 - val_loss: 0.3374 - val_accuracy: 0.8593\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8534 - val_loss: 0.3333 - val_accuracy: 0.8621\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3309 - accuracy: 0.8649 - val_loss: 0.3315 - val_accuracy: 0.8666\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3143 - accuracy: 0.8729 - val_loss: 0.3344 - val_accuracy: 0.8648\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3262 - accuracy: 0.8616 - val_loss: 0.3296 - val_accuracy: 0.8657\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3250 - accuracy: 0.8660 - val_loss: 0.3283 - val_accuracy: 0.8657\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.8699 - val_loss: 0.3343 - val_accuracy: 0.8657\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.8657 - val_loss: 0.3287 - val_accuracy: 0.8643\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8709 - val_loss: 0.3306 - val_accuracy: 0.8670\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3133 - accuracy: 0.8667 - val_loss: 0.3338 - val_accuracy: 0.8666\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.8710 - val_loss: 0.3281 - val_accuracy: 0.8666\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3088 - accuracy: 0.8740 - val_loss: 0.3280 - val_accuracy: 0.8711\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.2926 - accuracy: 0.8792 - val_loss: 0.3300 - val_accuracy: 0.8684\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.8744 - val_loss: 0.3278 - val_accuracy: 0.8666\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3045 - accuracy: 0.8739 - val_loss: 0.3296 - val_accuracy: 0.8643\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.3091 - accuracy: 0.8697 - val_loss: 0.3286 - val_accuracy: 0.8670\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.2997 - accuracy: 0.8766 - val_loss: 0.3305 - val_accuracy: 0.8688\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.2971 - accuracy: 0.8763 - val_loss: 0.3334 - val_accuracy: 0.8702\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.2874 - accuracy: 0.8807 - val_loss: 0.3309 - val_accuracy: 0.8675\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.2859 - accuracy: 0.8808 - val_loss: 0.3332 - val_accuracy: 0.8639\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.2809 - accuracy: 0.8870 - val_loss: 0.3327 - val_accuracy: 0.8666\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.2743 - accuracy: 0.8860 - val_loss: 0.3346 - val_accuracy: 0.8675\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.2955 - accuracy: 0.8774 - val_loss: 0.3357 - val_accuracy: 0.8643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.5604069232940674,\n",
       "  0.4382692575454712,\n",
       "  0.3883560597896576,\n",
       "  0.37111109495162964,\n",
       "  0.35807913541793823,\n",
       "  0.35679253935813904,\n",
       "  0.347476601600647,\n",
       "  0.34749364852905273,\n",
       "  0.3408835828304291,\n",
       "  0.3352910578250885,\n",
       "  0.32710227370262146,\n",
       "  0.3251993656158447,\n",
       "  0.32075414061546326,\n",
       "  0.31486231088638306,\n",
       "  0.31799766421318054,\n",
       "  0.31718748807907104,\n",
       "  0.3072964549064636,\n",
       "  0.31077519059181213,\n",
       "  0.3092276155948639,\n",
       "  0.30367082357406616,\n",
       "  0.3053053319454193,\n",
       "  0.29876306653022766,\n",
       "  0.30660584568977356,\n",
       "  0.3016033172607422,\n",
       "  0.2967414855957031,\n",
       "  0.28846511244773865,\n",
       "  0.29470938444137573,\n",
       "  0.29081088304519653,\n",
       "  0.2859611213207245,\n",
       "  0.29291263222694397],\n",
       " 'accuracy': [0.742348849773407,\n",
       "  0.8101914525032043,\n",
       "  0.8358209133148193,\n",
       "  0.8444142937660217,\n",
       "  0.8492386341094971,\n",
       "  0.8492386341094971,\n",
       "  0.8524046540260315,\n",
       "  0.8542137742042542,\n",
       "  0.8590381145477295,\n",
       "  0.8600934743881226,\n",
       "  0.864616334438324,\n",
       "  0.8662747144699097,\n",
       "  0.868536114692688,\n",
       "  0.8695914149284363,\n",
       "  0.8650686144828796,\n",
       "  0.8676315546035767,\n",
       "  0.868536114692688,\n",
       "  0.871099054813385,\n",
       "  0.872606635093689,\n",
       "  0.8715513348579407,\n",
       "  0.8717020750045776,\n",
       "  0.8774310350418091,\n",
       "  0.872305154800415,\n",
       "  0.877581775188446,\n",
       "  0.875018835067749,\n",
       "  0.8805969953536987,\n",
       "  0.8790894150733948,\n",
       "  0.8792401552200317,\n",
       "  0.8810492753982544,\n",
       "  0.8783355951309204],\n",
       " 'val_loss': [0.49082472920417786,\n",
       "  0.3784264624118805,\n",
       "  0.35952144861221313,\n",
       "  0.34681999683380127,\n",
       "  0.3403972089290619,\n",
       "  0.3369942903518677,\n",
       "  0.3346523940563202,\n",
       "  0.33735188841819763,\n",
       "  0.33325064182281494,\n",
       "  0.33151325583457947,\n",
       "  0.33438313007354736,\n",
       "  0.32958167791366577,\n",
       "  0.3283288776874542,\n",
       "  0.33430635929107666,\n",
       "  0.3287443220615387,\n",
       "  0.3305860757827759,\n",
       "  0.333783358335495,\n",
       "  0.3280545771121979,\n",
       "  0.3280475437641144,\n",
       "  0.33004873991012573,\n",
       "  0.32778534293174744,\n",
       "  0.32957005500793457,\n",
       "  0.328606516122818,\n",
       "  0.33051738142967224,\n",
       "  0.3334159851074219,\n",
       "  0.33090898394584656,\n",
       "  0.3331981599330902,\n",
       "  0.33266720175743103,\n",
       "  0.33458277583122253,\n",
       "  0.3356713354587555],\n",
       " 'val_accuracy': [0.7688828706741333,\n",
       "  0.8371777534484863,\n",
       "  0.8539122343063354,\n",
       "  0.8575305342674255,\n",
       "  0.8543645143508911,\n",
       "  0.8566259741783142,\n",
       "  0.8588873744010925,\n",
       "  0.8593396544456482,\n",
       "  0.862053394317627,\n",
       "  0.8665761947631836,\n",
       "  0.8647670745849609,\n",
       "  0.8656716346740723,\n",
       "  0.8656716346740723,\n",
       "  0.8656716346740723,\n",
       "  0.8643147945404053,\n",
       "  0.8670284748077393,\n",
       "  0.8665761947631836,\n",
       "  0.8665761947631836,\n",
       "  0.871099054813385,\n",
       "  0.868385374546051,\n",
       "  0.8665761947631836,\n",
       "  0.8643147945404053,\n",
       "  0.8670284748077393,\n",
       "  0.8688376545906067,\n",
       "  0.8701944947242737,\n",
       "  0.8674807548522949,\n",
       "  0.8638625144958496,\n",
       "  0.8665761947631836,\n",
       "  0.8674807548522949,\n",
       "  0.8643147945404053]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model(log_run_results  = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-plasma",
   "metadata": {},
   "source": [
    "## Output of the tests are deleted as the notebook will not load in Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-helping",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is very quick, so we can use grid search on these models.\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "\n",
    "# Write the header line\n",
    "with open(\"runs.log\",'a') as f:\n",
    "    f.write(\"timestamp|max_len|epochs|batch_size|embed_dim|num_filters|kernel_sizes|dense_layer_dims|dropout_rate|num_classes|train_embeds|\")\n",
    "    for metric in [ 'loss', 'accuracy', 'val_loss', 'val_accuracy']:\n",
    "        f.write(f\"{metric}|\")\n",
    "        for i in range(0,epochs):\n",
    "            f.write(f\"{metric}-{i}|\")\n",
    "    f.write(f\"END\\n\")        \n",
    "    f.close()\n",
    "\n",
    "    \n",
    "# run the models\n",
    "\n",
    "for k_sizes in [ [2,4], [4,8], [8,16], [2,3,4], [2,4,6], [2,6,8], [4,6,8], [4,8,12], [8,12,16] ]:\n",
    "\n",
    "    # Set filter counts according to the number of kernels in use.\n",
    "    if len(k_sizes) == 2:\n",
    "        filter_counts = [ [2,2], [4,4], [8,8], [2,4], [4,8], [8,16], [16,32] ]\n",
    "    if len(k_sizes) == 3:\n",
    "        filter_counts = [ [2,2,2], [4,4,4], [8,8,8], [2,3,4], [3,4,5], [4,5,6], [8,10,16], [8,16,32] ]\n",
    "    \n",
    "    \n",
    "    for n_fil in filter_counts:\n",
    "        for dld in [ [4], [8], [16], [32], [64], [4,4], [8,8], [16,16], [32,32], [4,4,4], [8,8,8], [16,16,16] ]:\n",
    "            for dropout in np.arange(0,0.9,0.2):\n",
    "                for tr in [True, False]:\n",
    "                    hist = run_model(epochs           = epochs,\n",
    "                                     kernel_sizes     = k_sizes,\n",
    "                                     num_filters      = n_fil,\n",
    "                                     dense_layer_dims = dld,\n",
    "                                     dropout_rate     = dropout,\n",
    "                                     train_embeds     = tr,\n",
    "                                     log_run_results  = True)\n",
    "                    print(\"\\n\\n\\n##########################################################################\\n\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-documentary",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "1. max_len = 100\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "embed_dim = 50\n",
    "\n",
    "num_filters = [2, 2, 2]\n",
    "\n",
    "kernel_sizes = [2, 3, 4]\n",
    "\n",
    "dense_layer_dims = [8]\n",
    "\n",
    "dropout_rate = 0.1\n",
    "\n",
    "train_embeds = False  # Whether we allow the embeddings to be changed\n",
    "\n",
    "opt = 'adam'\n",
    "\n",
    "opt = SGD(lr=0.1)\n",
    "\n",
    "opt = RMSprop(learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-parameter",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Dataset Citations\n",
    "\n",
    "@inproceedings{arslan2020claimbuster,\n",
    "    title={{A Benchmark Dataset of Check-worthy Factual Claims}},\n",
    "    author={Arslan, Fatma and Hassan, Naeemul and Li, Chengkai and Tremayne, Mark },\n",
    "    booktitle={14th International AAAI Conference on Web and Social Media},\n",
    "    year={2020},\n",
    "    organization={AAAI}\n",
    "}\n",
    "\n",
    "@article{meng2020gradient,\n",
    "  title={Gradient-Based Adversarial Training on Transformer Networks for Detecting Check-Worthy Factual Claims},\n",
    "  author={Meng, Kevin and Jimenez, Damian and Arslan, Fatma and Devasier, Jacob Daniel and Obembe, Daniel and Li, Chengkai},\n",
    "  journal={arXiv preprint arXiv:2002.07725},\n",
    "  year={2020}\n",
    "}\n",
    "\n",
    "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
    "\n",
    "\n",
    "### Useful resources in building this\n",
    "Using pre-trained word embeddings: https://keras.io/examples/nlp/pretrained_word_embeddings/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
