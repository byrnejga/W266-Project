{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "streaming-tenant",
   "metadata": {},
   "source": [
    "## Comparison Approach\n",
    "This notebook loads each of the individual, trained models from the best runs of both Bert and CNN-based approaches. It will show the model.summary() and diagram, then will run a performance test by inferring results for the texts in the ClaimBuster dataset's crowdsourced.csv file. The file contains 22501 sentences. We will use sentences per second as the performance metric, and the on-disk size of each model as the complexity metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aware-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Usual Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import string\n",
    "\n",
    "import json\n",
    "\n",
    "# to fix the CUDA issues for CUDA 11.2 to allow use of the GPU\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "capital-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and parse the crowdsourced.csv file\n",
    "\n",
    "cs = pd.read_csv(\"../data/crowdsourced.csv\", delimiter=',', quotechar = '\"', index_col='Sentence_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-sunrise",
   "metadata": {},
   "source": [
    "Unlike the curated json dataset we used for training, the \"verdict\" column takes three values:\n",
    "\n",
    "| Verdict | Description |\n",
    "| :---: | :--- |\n",
    "| +1 | Checkable Fact Statements, e.g. \"Inflation is down 2%\" |\n",
    "| 0 | Uncheckable Fact Statements, e.g. \"Jack likes fish\" |\n",
    "| -1 | Non Fact Statements, e.g. \"Drink the water\" |\n",
    "\n",
    "For the purposes of this paper, we are only interested in checkable fact statements, so we set any -1 verdicts to equal zero before tokenizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "featured-liechtenstein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'Speaker', 'Speaker_title', 'Speaker_party', 'File_id',\n",
       "       'Length', 'Line_number', 'Sentiment', 'Verdict'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sized-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence_id\n",
       "16       False\n",
       "17       False\n",
       "18       False\n",
       "19       False\n",
       "20       False\n",
       "         ...  \n",
       "34451    False\n",
       "34455    False\n",
       "34456    False\n",
       "34457    False\n",
       "34458    False\n",
       "Name: Verdict, Length: 14685, dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change -1 verdicts to 0\n",
    "cs.loc[cs[\"Verdict\"] == -1][\"Verdict\"] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "demographic-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will need different lengths of tokenization depending on the model\n",
    "\n",
    "def tokenize_from_json(sentences, max_len=100):\n",
    "\n",
    "    # Load the tokenizer from the stored json file created from\n",
    "    # the original training data\n",
    "    with open('./tokenizer.json') as f:\n",
    "        data = json.load(f)\n",
    "        t = keras.preprocessing.text.tokenizer_from_json(data)\n",
    "    \n",
    "    # Convert to word IDs and pad each sentences out to max_length\n",
    "    tokens = pad_sequences(t.texts_to_sequences(sentences),\n",
    "                           max_len,\n",
    "                           padding='post',\n",
    "                           truncating='post')\n",
    "    \n",
    "    vocab_list = list(t.word_index.keys())\n",
    "           \n",
    "    return tokens, vocab_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-fields",
   "metadata": {},
   "source": [
    "## Now we have set up the tokenization function based on the tokenizer and vocabulary generated from the original training sets, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "chicken-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, vocab_list = tokenize_from_json(cs[\"Text\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "another-intelligence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22501, 100)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-writer",
   "metadata": {},
   "source": [
    "### Citations\n",
    "@inproceedings{arslan2020claimbuster,\n",
    "    title={{A Benchmark Dataset of Check-worthy Factual Claims}},\n",
    "    author={Arslan, Fatma and Hassan, Naeemul and Li, Chengkai and Tremayne, Mark },\n",
    "    booktitle={14th International AAAI Conference on Web and Social Media},\n",
    "    year={2020},\n",
    "    organization={AAAI}\n",
    "}\n",
    "\n",
    "@article{meng2020gradient,\n",
    "  title={Gradient-Based Adversarial Training on Transformer Networks for Detecting Check-Worthy Factual Claims},\n",
    "  author={Meng, Kevin and Jimenez, Damian and Arslan, Fatma and Devasier, Jacob Daniel and Obembe, Daniel and Li, Chengkai},\n",
    "  journal={arXiv preprint arXiv:2002.07725},\n",
    "  year={2020}\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
