{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "raised-wealth",
   "metadata": {},
   "source": [
    "## Analysis of Fine Tuning Runs\n",
    "\n",
    "Analysis and charts to interpret the output from the second run to fine tune - this time with balanced training data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "increased-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Add mathematical libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Graphical libraries and items.\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots, draw\n",
    "\n",
    "\n",
    "import re\n",
    "# import json\n",
    "# import datetime\n",
    "# import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "injured-personality",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './runs2bal.log'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4ab40ba278ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfile_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./runs2bal.log\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             )\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \"\"\"\n\u001b[0;32m-> 1357\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1358\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './runs2bal.log'"
     ]
    }
   ],
   "source": [
    "## Read file into Pandas Data array\n",
    "\n",
    "file_loc = \"./runs2bal.log\"\n",
    "\n",
    "df = pd.read_csv(file_loc, sep='|', skiprows=(), header=(0))\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find max accuracy and min loss on training and\n",
    "### validation sets, and which epoch it was achieved on\n",
    "### This will let us see both the most accurate runs\n",
    "### and let us detect if (a) convergence has occurred\n",
    "### and (b) whether we have overfit the model\n",
    "\n",
    "epochs = 20  #output columns are counted from 0\n",
    "\n",
    "### Metrics are tuples of the metric name and + or -1\n",
    "### depending whether low or high numbers are best\n",
    "\n",
    "for metric in [ ('loss', -1), ('accuracy',1), ('val_loss',-1), ('val_accuracy',1)]:\n",
    "    best_val     = f\"{metric[0]}-best\"\n",
    "    best_epc = f\"{metric[0]}-epoch\"\n",
    "    met_sign     = metric[1]\n",
    "    \n",
    "    # Create list of the column names we want to check for the metric\n",
    "    metric_cols  = [ f\"{metric[0]}-{epoch}\" for epoch in range(0,epochs) ]\n",
    "   \n",
    "\n",
    "    # for some reason, pd.read_csv is interpreting \n",
    "\n",
    "\n",
    "    # Find the best value for each metric, as well as the epoch in which it occurred\n",
    "    #\n",
    "    # idxmax(axis=1) returns the column name with the maximum value, idxmin does\n",
    "    # the sames for the minimum\n",
    "    #\n",
    "    # The str.extract() turns the values into strings and then pulls out only digits\n",
    "    # Ordinarily this would also pull separators like \",\" and \".\" as well, but\n",
    "    # we don't have them in the column names.\n",
    "    \n",
    "    if met_sign == 1:\n",
    "        df[best_val] = df[metric_cols].max(axis=1)\n",
    "        df[best_epc] = df[metric_cols].idxmax(axis=1).str.extract('(\\d+)').astype(int)\n",
    "    else:\n",
    "        df[best_val] = df[metric_cols].min(axis=1)\n",
    "        df[best_epc] = df[metric_cols].idxmin(axis=1).str.extract('(\\d+)').astype(int)\n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-faculty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_cols = metric_cols.copy()\n",
    "\n",
    "temp_cols.append(best_val)\n",
    "temp_cols.append(best_epc)\n",
    "# df[temp_cols]\n",
    "# type(best_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-roman",
   "metadata": {},
   "source": [
    "## Review Results by each of the hyperparameters we are varying\n",
    "\n",
    "Unless otherwise stated, we will be measuring loss and accuracy for the validation data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Top values\n",
    "### Absolute best value\n",
    "df.sort_values('val_accuracy-best', ascending=False)[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-vehicle",
   "metadata": {},
   "source": [
    "### Look at the effect of the convolutional filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = df.boxplot(column=[\"val_accuracy-best\"], by=['kernel_sizes'], figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = df.boxplot(column=[\"val_accuracy-epoch\"], by=['kernel_sizes'], figsize=(20,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-blues",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# look at each set of kernel sizes by their counts\n",
    "\n",
    "kernels = df.kernel_sizes.unique()\n",
    "\n",
    "# create 3-wide subplots to show\n",
    "fig, ax = plt.subplots(nrows=5, ncols=2, figsize=(20, 30), sharey=True)\n",
    "\n",
    "for i in range(0,len(kernels)):\n",
    "      \n",
    "    x = i // 2\n",
    "    y = i % 2\n",
    "    \n",
    "    axis = ax[x,y]\n",
    "    \n",
    "    axis.set_ylabel(\"val_accuracy-best\")\n",
    "\n",
    "    # plt.xticks(rotation = 45) # Rotates X-Axis Ticks by 45-degrees\n",
    "    boxplot = df[df.kernel_sizes == kernels[i]].boxplot(column=[\"val_accuracy-best\"],\n",
    "                                                          by=['num_filters'],\n",
    "                                                          ax=axis,\n",
    "                                                          figsize=(20,10))\n",
    "    axis.title.set_text(f\"Kernel Sizes: {kernels[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-sterling",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# look at each set of filter counts by their kernel sizes\n",
    "\n",
    "filters = df.num_filters.unique()\n",
    "\n",
    "# create 3-wide subplots to show\n",
    "# fig, ax = plt.subplots(nrows=8, ncols=2, figsize=(20, 50), sharey=True)\n",
    "fig, ax = plt.subplots(nrows=7, ncols=2, figsize=(20, 50), sharey=True)\n",
    "\n",
    "for i in range(0,len(filters)):\n",
    "      \n",
    "    x = i // 2\n",
    "    y = i % 2\n",
    "    \n",
    "    axis = ax[x,y]\n",
    "    \n",
    "    axis.set_ylabel(\"val_accuracy-best\")\n",
    "\n",
    "    # plt.xticks(rotation = 45) # Rotates X-Axis Ticks by 45-degrees\n",
    "    boxplot = df[df.num_filters == filters[i]].boxplot(column=[\"val_accuracy-best\"],\n",
    "                                                          by=['kernel_sizes'],\n",
    "                                                          ax=axis,\n",
    "                                                          figsize=(20,10))\n",
    "    axis.title.set_text(f\"Filter counts: {filters[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-formula",
   "metadata": {},
   "source": [
    "**In all of the cases we tried, the best accuracies came from the highest number of filters for each set of kernels, regardless of the kernel sizes:** ```[16,32]``` for the two-filter convolutions and ```[8,16,32]``` for the three-filter ones. We should therefore test even higher counts to see if that makes any marginal improvement, including ```[32,64]``` for the two-filter convolutions, and ```[16,32,63]``` for the three-filter ones.\n",
    "\n",
    "**Equally, the largest filters generally produce the best results,** though there seems to be some fall off between ```[4,9,12]``` and ```[8,12,16]``` suggesting that a 4-word kernel does have value.  We should, in addition, test [4,8,16], [4,8,16,32] and other similar combinations to see if we can improve further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-rwanda",
   "metadata": {},
   "source": [
    "## Evaluate the Dense Layers\n",
    "Look at differences in the fully connected layers within the beset selections so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at accuracy by dense layers\n",
    "\n",
    "boxplot = df.plot.bar(x=\"dense_layer_dims\", y='val_accuracy-best', figsize=(20,10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-credits",
   "metadata": {},
   "source": [
    "**After selecting the best from the rest of the hyperparameters, the dense layers have less of an effect (within 1% of accuracy) - a single layer of only 8 nodes appears to be sufficient to give a good result.**\n",
    "\n",
    "As we have a relatively small data set for training - fewer than 7000 records in training, it may not be possible to effectively converge on larger dense-layer models.\n",
    "\n",
    "We also may want to look at f1 instead of accuracy to be certain??\n",
    "\n",
    "Round 1 testing was for 8280 tests with different hyperparameters in a total run time of 49h40m for an average of 1 test every 21.6s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-rings",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_test = df3[ df3[\"dense_layer_dims\"] == \"[8]\"].to_dict(orient='records')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "## print out best version:\n",
    "\n",
    "print(f\"Best validation accuracy in first hyperparameter tuning run is {best_test['val_accuracy-best']:5f}, in epoch {best_test['val_accuracy-epoch']},  Run at: {best_test['timestamp']}\")\n",
    "\n",
    "print(f\"Model:  num_filters: {best_test['num_filters']}, kernel_sizes: {best_test['kernel_sizes']},  dense_layer_dims: {best_test['dense_layer_dims']},  dropout_rate: {best_test['dropout_rate']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
